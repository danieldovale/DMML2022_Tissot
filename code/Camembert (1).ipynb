{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Mining and Machine Learning - Team Tissot**\n",
        "## **CamemBERT**"
      ],
      "metadata": {
        "id": "1Ty8ByVfiH7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ⚠️ Disclaimer: This Colab notebook contains the steps to train a CamemBERT model using code that was taken from this [article.](https://www.kaggle.com/code/houssemayed/camembert-for-french-tweets-classification/notebook#CamemBERT-for-text-classification-task)\n",
        ">\n",
        ">Please note that we did not write this code ourselves and were simply using it for curiosity and testing purposes. Any submissions to Kaggle using this model were done after the competition deadline.\n",
        ">\n",
        ">\n"
      ],
      "metadata": {
        "id": "bzEQ5sSKiWK6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhN6ZB0v2F_s",
        "outputId": "ca3c39e4-a68d-430f-8c97-9b613b3d0719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "# In the beginning let's install transformers library\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaPPNcfu2O5A"
      },
      "outputs": [],
      "source": [
        "# Importing standard libraries for every machine/deep learning pipeline\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm, trange\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Importing specific libraries for data prerpcessing, model archtecture choice, training and evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
        "from transformers import AdamW\n",
        "# import torch.optim as optim\n",
        "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "# import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvWD5ZIy2R8e"
      },
      "outputs": [],
      "source": [
        "# Defining constants\n",
        "epochs = 3\n",
        "MAX_LEN = 128\n",
        "batch_size = 16\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NEchA4U2Zae"
      },
      "outputs": [],
      "source": [
        "dfTrain = pd.read_csv(\"https://raw.githubusercontent.com/danieldovale/DMML2022_Tissot/main/data/training_data.csv\", index_col='id')\n",
        "\n",
        "# unlabeled test data:\n",
        "dfTest = pd.read_csv(\"https://raw.githubusercontent.com/danieldovale/DMML2022_Tissot/main/data/unlabelled_test_data.csv\", index_col='id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFpY8zWo5KYH"
      },
      "outputs": [],
      "source": [
        "dfTrain['difficulty'] = dfTrain['difficulty'].replace(['A1','A2','B1', 'B2', 'C1', 'C2'],[0,1,2,3,4,5]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "l-0JVBp35VsY",
        "outputId": "2f1d308d-cc6f-4cbd-d9bb-799828194ad6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  difficulty\n",
              "id                                                                 \n",
              "0     Les coûts kilométriques réels peuvent diverger...           4\n",
              "1     Le bleu, c'est ma couleur préférée mais je n'a...           0\n",
              "2     Le test de niveau en français est sur le site ...           0\n",
              "3              Est-ce que ton mari est aussi de Boston?           0\n",
              "4     Dans les écoles de commerce, dans les couloirs...           2\n",
              "...                                                 ...         ...\n",
              "4795  C'est pourquoi, il décida de remplacer les hab...           3\n",
              "4796  Il avait une de ces pâleurs splendides qui don...           4\n",
              "4797  Et le premier samedi de chaque mois, venez ren...           1\n",
              "4798  Les coûts liés à la journalisation n'étant pas...           5\n",
              "4799  Sur le sable, la mer haletait de toute la resp...           5\n",
              "\n",
              "[4800 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e79df006-9c8e-4505-a906-1e975b142765\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Le test de niveau en français est sur le site ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>C'est pourquoi, il décida de remplacer les hab...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>Il avait une de ces pâleurs splendides qui don...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>Et le premier samedi de chaque mois, venez ren...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>Les coûts liés à la journalisation n'étant pas...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>Sur le sable, la mer haletait de toute la resp...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e79df006-9c8e-4505-a906-1e975b142765')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e79df006-9c8e-4505-a906-1e975b142765 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e79df006-9c8e-4505-a906-1e975b142765');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "dfTrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeTp_VvS3Qjx",
        "outputId": "070a600c-0193-483c-82b3-258282a7a7f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n"
          ]
        }
      ],
      "source": [
        "pip install sentencepiece "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faj_BwbB3Zbb"
      },
      "outputs": [],
      "source": [
        "from transformers import CamembertModel, CamembertTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwDScCiN2vwo"
      },
      "outputs": [],
      "source": [
        "# Initialize CamemBERT tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base',do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcKyGcAE4C31"
      },
      "outputs": [],
      "source": [
        "# Creates list of texts and labels\n",
        "text = dfTrain['sentence'].to_list()\n",
        "labels = dfTrain['difficulty'].to_list()\n",
        "\n",
        "#user tokenizer to convert sentences into tokenizer\n",
        "input_ids  = [tokenizer.encode(sent,add_special_tokens=True,max_length=MAX_LEN, truncation=True) for sent in text]\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]  \n",
        "    attention_masks.append(seq_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpx6ddtL4wEI"
      },
      "outputs": [],
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(input_ids, labels, attention_masks,\n",
        "                                                            random_state=42, test_size=0.1)\n",
        "\n",
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIxPLOGR4kYL"
      },
      "outputs": [],
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
        "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=6)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4w1aCI75pTe",
        "outputId": "c8cad546-74f9-42cf-94b6-4741f4344811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps=10e-8)\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp_uGzbH55v_",
        "outputId": "3efd41cb-1de5-45e7-a6b1-66cebd58e92c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.4350167841823012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  33%|███▎      | 1/3 [01:29<02:59, 89.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.46458333333333335\n",
            "Train loss: 1.0447857196684236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|██████▋   | 2/3 [03:02<01:31, 91.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.5375\n",
            "Train loss: 0.8547435464682402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 3/3 [04:35<00:00, 91.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.5395833333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Store our loss and accuracy for plotting if we want to visualize training evolution per epochs after the training process\n",
        "train_loss_set = []\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):  \n",
        "    # Tracking variables for training\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "    # Train the model\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Add batch to device CPU or GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Clear out the gradients (by default they accumulate)\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        outputs = model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        # Get loss value\n",
        "        loss = outputs[0]\n",
        "        # Add it to train loss list\n",
        "        train_loss_set.append(loss.item())    \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        # Update parameters and take a step using the computed gradient\n",
        "        optimizer.step()\n",
        "    \n",
        "        # Update tracking variables\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    # Tracking variables for validation\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    # Validation of the model\n",
        "    model.eval()\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        # Add batch to device CPU or GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions\n",
        "            outputs =  model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "            loss, logits = outputs[:2]\n",
        "    \n",
        "        # Move logits and labels to CPU if GPU is used\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = dfTest['sentence'].to_list()"
      ],
      "metadata": {
        "id": "9EWJyms3qPxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenized_comments_ids = [tokenizer.encode(comment,add_special_tokens=True,max_length=MAX_LEN) for comment in text_test]\n",
        "# Pad the resulted encoded comments\n",
        "tokenized_comments_ids = pad_sequences(tokenized_comments_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks \n",
        "attention_masks = []\n",
        "for seq in tokenized_comments_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "\n",
        "prediction_inputs = torch.tensor(tokenized_comments_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OKvTCAvqb4A",
        "outputId": "b020ea93-75b3-4598-e6eb-605ce3f21b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the finetuned model (Camembert)\n",
        "flat_pred = []\n",
        "with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    outputs =  model(prediction_inputs.to(device),token_type_ids=None, attention_mask=prediction_masks.to(device))\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy() \n",
        "    flat_pred.extend(np.argmax(logits, axis=1).flatten())"
      ],
      "metadata": {
        "id": "kwSdzcsUqjSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_pred"
      ],
      "metadata": {
        "id": "7d3_GIvYqnSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_pred_txt = flat_pred.replace([0,1,2,3,4,5],['A1','A2','B1', 'B2', 'C1', 'C2']) "
      ],
      "metadata": {
        "id": "wNXKtLFjqx_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map_list = ['A1','A2','B1','B2','C1','C2']\n",
        "new_list = []\n",
        "\n",
        "for i in flat_pred:\n",
        "    if i == 0:\n",
        "        new_list.append(\"A1\")\n",
        "    elif i == 1:\n",
        "        new_list.append(\"A2\")\n",
        "    elif i == 2:\n",
        "        new_list.append(\"B1\")\n",
        "    elif i == 3:\n",
        "        new_list.append(\"B2\")\n",
        "    elif i == 4:\n",
        "        new_list.append(\"C1\")\n",
        "    else:\n",
        "        new_list.append(\"C2\")\n",
        "\n",
        "new_list"
      ],
      "metadata": {
        "id": "KxrcqUI7q94j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "OvBqNJS9rdQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEWDF = pd.DataFrame(data = new_list)\n",
        "NEWDF.index.names = ['id']\n",
        "NEWDF.rename(columns = {0:'difficulty'}, inplace = True)\n",
        "NEWDF.to_csv('submissionTest.csv')\n",
        "files.download('submissionTest.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "pA5-dxSSrbni",
        "outputId": "bc2e50f1-cf5a-41e9-f2bc-f36c7e5be138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_42986922-dab2-4655-8dee-51f652f3ec66\", \"submissionTest.csv\", 8504)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Disclaimer: those submissions were done after the deadline and did not count towards the competition.\n",
        "\n",
        "  **Submission score** with epochs set to 3: **`0.505`**\n",
        "\n",
        "**Submission score** with epochs set to 5:  **`0.54`**\n",
        "\n"
      ],
      "metadata": {
        "id": "3W9IxE1OhXia"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}